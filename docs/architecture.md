# Virtual Assistant Architecture Design

## üèõÔ∏è SOLID Principles Implementation

### Single Responsibility Principle (SRP)
- **ModelManager**: Only handles model loading/unloading
- **ConversationManager**: Only manages chat history and context
- **VoiceService**: Only handles TTS/STT operations
- **ToolRegistry**: Only manages external tool integrations
- **WebInterface**: Only handles HTTP endpoints and UI

### Open/Closed Principle (OCP)
- **ToolBase**: Abstract base class for extending tools
- **ModelProvider**: Interface for different model backends
- **VoiceProvider**: Interface for different voice engines

### Liskov Substitution Principle (LSP)
- Any **ModelProvider** can replace another (OpenVINO, ONNX, etc.)
- Any **VoiceProvider** can replace another (Whisper, SpeechT5, etc.)

### Interface Segregation Principle (ISP)
- **ITextGenerator**: Only text generation methods
- **IChatModel**: Only chat-specific methods  
- **IVoiceInput**: Only speech-to-text methods
- **IVoiceOutput**: Only text-to-speech methods

### Dependency Inversion Principle (DIP)
- High-level modules depend on abstractions, not concrete implementations
- Dependency injection through FastAPI's DI system

## üìÅ Project Structure

```
wiwin/
‚îú‚îÄ‚îÄ core/                           # Core business logic
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ interfaces/                 # Abstract interfaces
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_provider.py       # IModelProvider, ITextGenerator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice_provider.py       # IVoiceInput, IVoiceOutput
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool_provider.py        # IToolProvider
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ storage_provider.py     # IStorageProvider
‚îÇ   ‚îú‚îÄ‚îÄ models/                     # Data models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversation.py         # Conversation, Message models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice.py               # VoiceRequest, VoiceResponse
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool.py                # ToolRequest, ToolResponse
‚îÇ   ‚îî‚îÄ‚îÄ exceptions/                 # Custom exceptions
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ model_exceptions.py
‚îÇ       ‚îú‚îÄ‚îÄ voice_exceptions.py
‚îÇ       ‚îî‚îÄ‚îÄ tool_exceptions.py
‚îú‚îÄ‚îÄ services/                       # Business logic services
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ model_manager.py           # Model loading and inference
‚îÇ   ‚îú‚îÄ‚îÄ conversation_manager.py    # Chat history and context
‚îÇ   ‚îú‚îÄ‚îÄ voice_service.py           # TTS/STT orchestration
‚îÇ   ‚îú‚îÄ‚îÄ tool_registry.py           # Tool management and execution
‚îÇ   ‚îî‚îÄ‚îÄ intel_optimizer.py         # Intel hardware optimization
‚îú‚îÄ‚îÄ providers/                      # Concrete implementations
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Model providers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openvino_provider.py   # OpenVINO implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fallback_provider.py   # CPU fallback
‚îÇ   ‚îú‚îÄ‚îÄ voice/                     # Voice providers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ whisper_provider.py    # Whisper STT
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ speecht5_provider.py   # SpeechT5 TTS
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # Tool providers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gmail_tool.py          # Gmail integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_search_tool.py     # Web search
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_tool.py           # File operations
‚îÇ   ‚îî‚îÄ‚îÄ storage/                   # Storage providers
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ sqlite_provider.py     # SQLite for conversations
‚îÇ       ‚îî‚îÄ‚îÄ redis_provider.py      # Redis for caching
‚îú‚îÄ‚îÄ api/                           # API layer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py           # FastAPI dependencies
‚îÇ   ‚îú‚îÄ‚îÄ middleware.py             # Custom middleware
‚îÇ   ‚îú‚îÄ‚îÄ routes/                   # API routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py               # Chat endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice.py              # Voice endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.py              # Tool endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py             # Health and metrics
‚îÇ   ‚îî‚îÄ‚îÄ schemas/                  # Pydantic schemas
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ chat_schemas.py
‚îÇ       ‚îú‚îÄ‚îÄ voice_schemas.py
‚îÇ       ‚îî‚îÄ‚îÄ tool_schemas.py
‚îú‚îÄ‚îÄ web/                          # Web interface
‚îÇ   ‚îú‚îÄ‚îÄ static/                   # Static files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ templates/                # HTML templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.html
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.html
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ config/                       # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings.py               # Application settings
‚îÇ   ‚îú‚îÄ‚îÄ intel_profiles.py         # Hardware-specific configs
‚îÇ   ‚îî‚îÄ‚îÄ model_configs.py          # Model configurations
‚îú‚îÄ‚îÄ tests/                        # Testing
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ unit/                     # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ integration/              # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ performance/              # Performance benchmarks
‚îú‚îÄ‚îÄ scripts/                      # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup_models.py           # Download and setup models
‚îÇ   ‚îú‚îÄ‚îÄ benchmark.py              # Performance testing
‚îÇ   ‚îî‚îÄ‚îÄ deploy.py                 # Deployment automation
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ intel_optimized_models.md
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md
‚îÇ   ‚îî‚îÄ‚îÄ api_reference.md
‚îú‚îÄ‚îÄ docker/                       # Docker configurations
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.intel          # Intel-optimized container
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.intel.yml  # Intel-specific compose
‚îÇ   ‚îî‚îÄ‚îÄ intel-runtime.yml         # Intel runtime setup
‚îú‚îÄ‚îÄ requirements/                 # Requirements files
‚îÇ   ‚îú‚îÄ‚îÄ base.txt                 # Core dependencies
‚îÇ   ‚îú‚îÄ‚îÄ intel.txt                # Intel-specific deps
‚îÇ   ‚îú‚îÄ‚îÄ dev.txt                  # Development dependencies
‚îÇ   ‚îî‚îÄ‚îÄ test.txt                 # Testing dependencies
‚îî‚îÄ‚îÄ main.py                      # Application entry point
```

## üîÑ Component Interaction Flow

### Chat Flow
```
Web Interface ‚Üí Chat Route ‚Üí Conversation Manager ‚Üí Model Manager ‚Üí OpenVINO Provider ‚Üí Intel Arc GPU
```

### Voice Flow
```
Web Interface ‚Üí Voice Route ‚Üí Voice Service ‚Üí [Whisper Provider ‚Üí Intel NPU] + [SpeechT5 Provider ‚Üí Intel NPU]
```

### Tool Flow
```
Chat Message ‚Üí Tool Registry ‚Üí [Gmail Tool | Web Search Tool | File Tool] ‚Üí External API/System
```

## üß© Dependency Injection Pattern

### Service Registration
```python
# In main.py or startup
def configure_services():
    # Model providers
    container.register(IModelProvider, OpenVINOProvider, scope="singleton")
    
    # Voice providers  
    container.register(IVoiceInput, WhisperProvider, scope="singleton")
    container.register(IVoiceOutput, SpeechT5Provider, scope="singleton")
    
    # Storage providers
    container.register(IStorageProvider, SQLiteProvider, scope="singleton")
    
    # Services
    container.register(ModelManager, scope="singleton")
    container.register(ConversationManager, scope="singleton")
    container.register(VoiceService, scope="singleton")
    container.register(ToolRegistry, scope="singleton")
```

## üöÄ Intel Hardware Optimization Strategy

### Device Selection Logic
```python
class IntelOptimizer:
    def select_optimal_device(self, task_type: str) -> str:
        if task_type == "llm_inference":
            return "GPU" if self.has_arc_gpu() else "CPU"
        elif task_type in ["tts", "stt", "small_llm"]:
            return "NPU" if self.has_npu() else "CPU"
        else:
            return "CPU"
    
    def get_model_config(self, model_name: str, device: str) -> dict:
        return self.intel_profiles[model_name][device]
```

### Performance Monitoring
```python
class PerformanceMonitor:
    def track_inference_time(self, model: str, device: str, duration: float):
        # Track performance metrics for optimization
        
    def suggest_optimization(self) -> List[str]:
        # Analyze performance and suggest improvements
```

## üîê Error Handling Strategy

### Exception Hierarchy
```python
class AssistantException(Exception):
    """Base exception for the assistant"""

class ModelException(AssistantException):
    """Model-related errors"""

class VoiceException(AssistantException):
    """Voice processing errors"""

class ToolException(AssistantException):
    """Tool execution errors"""
```

### Graceful Degradation
1. **GPU unavailable** ‚Üí Fallback to CPU
2. **NPU unavailable** ‚Üí Fallback to CPU for voice
3. **Model loading failed** ‚Üí Use smaller backup model
4. **Tool unavailable** ‚Üí Inform user and suggest alternatives

## üìä Configuration Management

### Environment-based Configuration
```python
class Settings:
    # Intel Hardware
    use_arc_gpu: bool = True
    use_npu: bool = True
    fallback_to_cpu: bool = True
    
    # Models
    primary_llm: str = "qwen2.5-7b-int4"
    fallback_llm: str = "phi-3-mini-int4"
    tts_model: str = "speecht5"
    stt_model: str = "whisper-base"
    
    # Performance
    max_concurrent_requests: int = 4
    model_cache_size: int = 2
    conversation_history_limit: int = 100
```

This architecture ensures:
- ‚úÖ **Modularity**: Each component has a single responsibility
- ‚úÖ **Extensibility**: Easy to add new models, tools, or providers
- ‚úÖ **Testability**: Each component can be tested in isolation
- ‚úÖ **Intel Optimization**: Hardware-specific optimizations throughout
- ‚úÖ **Maintainability**: Clean separation of concerns
- ‚úÖ **Scalability**: Can handle multiple concurrent users